---
title: "The way I solved Syngenta Challenge 2020"
author: "Omer Perach"
date: '2020-06-18'
description: ''
slug: the-way-i-solved-syngenta-challenge-2020
tags: Data Science
categories:
- Plant Science
- Big Data
topics: []
---


```{r include=FALSE}
rm(list=ls())
library(ggplot2)
library(devtools)
library(dplyr)
library(h2o)
maize_data_train<-read.csv("CC2020_train_final.csv",header = TRUE)
```
#### The Challenge Purpose 
Commercial corn is one of the most important crops in the world.Every year plant breeders produce new corn products known as hybrids. Those hybrids are the products of crossing two "parents" called inbred. The most demanding and resource consuming procedure is to develop inbreds and subsequently assess the crossing outcome - hybrid - of one inbred to another inbred called 'tester'.

#### The importance of this project
On 2050 world population will approximately be 10 billion people. In order to feed 10 billion people the agriculture industry need to increase yield by almost 70%. Computational power with statistical abilities can help the breeders to achieve faster increase in yield results with less resources.

#### The Research Question
Given historical hybrid ("child" hybrid of inbred and tester) performance data across years and locations, how can we create a model to predict/impute the performance of the crossing of any two inbred and tester parents?

#### The data sets Syngenta provided
Syngenta provided two data sets, the first one for training a statistical model called *CC2020_train_final* and a testing data sets called *CC2020_test_final*.

#### Looking on the data

```{r echo=FALSE}
summary(maize_data_train)
```
##### Variables 
1. Year - two numbers representing three consecutive years 2016,2017,2018. 
2. Location - 280 different location where the experiment (crossing tester and inbred) took place.
3. INBRED - 593 unique inbred lines, meaning corn plants which used to be crossed with tester (other inbred).
4. INBRED CLUSTER - 14 different genetic "sign". Cluster association for each inbred which denotes genetic "grouping "sign".
5. TESTER - 496 unique tester lines.
6. TESTER CLUSTER - 13 genetic different genetic "sign". Cluster association for each inbred which denotes genetic "grouping "sign".
7. YIELD - The performance of the INBRED and TESTER "child" - hybrid.

Reviewing the data set using the `summary(maize_data_train)` we can start to understand the features of the data sets.  
Some questions:  
1. The relevance of YEAR feature - crossing two corn parents at 2016 do not influence any crossing done on 2018 and in addition for future yield prediction we will not want the model to learn the correlation between year and yield. In the following graph you can see box-plot for YIELD year. As we can see the differences are minor between year to year.  
2. We can see that some INBRED and TESTER have more observations than others INBRED and Tester lines. For example INBRED_3577 appear in 16448 observations while INBRED_3521 in 3202 observations. Do we need to split to test and train accordingly?

**H2O.ai** company developed AI open source infrastructure with strong machine learning algorithms.

##### Model Development Stages

1. House Keeping Models - Distributed Random Forest and Gradient Boosting Machine
2. Best Effort - Modeling Approach Improvement
3. Finish - Acceptance test

##### Personal note
I am coming from molecular biology background where mechanism and causality need to be proved by different methods. In regards to this challenge, I think that Syngenta need to invest in understanding how genes influence yield from the mechanism point of view. It is helpful to use machine in order to be more efficient but the main goal is to connect genes to phenotype. 

### House Keeping Models

The data set provided by Syngenta have 199476 observations. I will split the train data set into 80% that will serve for building the model, a K-fold cross validation will be used. On the other 20% I will test the models accuracy. I will also select out the year column out of the data frame. 

```{r echo=TRUE}
set.seed(42)
h2o.init()
df<-h2o.uploadFile("CC2020_train_final.csv")
df<-df[,-1]
train_test<-h2o.splitFrame(df,ratios = 0.8)
df_train<-train_test[[1]]
nrow(df_train)
df_test<-train_test[[2]]
nrow(df_test)
```

As you can see we divided the training data provided by Syngenta to two data sets, a *df_train* and a *df_test*, the train data set comprise ~159557 observations and the test ~39919 observations.

#### Training the three house keeping models
1. Distributed Random Forest 
2. Gradient Boosting Machine


#### Distributed Random Forest
```{r echo=TRUE}
ran_forest<-h2o.randomForest(model_id = "Random_Forest",x=c("LOCATION","INBRED","INBRED_CLUSTER","TESTER","INBRED","INBRED_CLUSTER","TESTER","TESTER_CLUSTER"),y="YIELD",training_frame = df_train,nfolds = 5,validation_frame = df_test)
performance_rf<-h2o.performance(ran_forest,df_test)
performance_rf
r2_for_tes_rf<-h2o.r2(ran_forest,valid = T)
r2_for_tes_rf
#performance of the model on the 20% test set
```
#### Gradient Boosting Machine
```{r echo=TRUE}
ran_gbm<-h2o.gbm(x=c("LOCATION","INBRED","INBRED_CLUSTER","TESTER","INBRED","INBRED_CLUSTER","TESTER","TESTER_CLUSTER"),y="YIELD",training_frame = df_train,nfolds = 5,validation_frame = df_test)
performance_gbm<-h2o.performance(ran_gbm)
performance_gbm
r2_for_tes_gbm<-h2o.r2(ran_gbm,valid = T)
r2_for_tes_gbm
```

Now we will compare between the two benchmark by each of the following parameters:
1. R squared
2. Mean Squared Error - MSE
3. Root Mean Squared Error - RMSE
4. Root mean Squared Logarithmic Error - RMSLE
5. Mean Absolute Error - MAE

R squared for the Distributed Random Forest model:
```{r echo=FALSE}
r2_for_tes_rf
```
R squared for the Gradient Boosting Machine:
```{r echo=FALSE}
r2_for_tes_gbm
```
The R squared of both of the models are low, with random forest model higher by 0.01, let's remember that R squared show us how good the predicted variable fit to a linear relationship, and maybe this is not the relationship in our data. In addition, good models can have low R squared.

The RMSE and the MAE are two parameters which thier units are the same as the predicted units. YIELD values go between 0.047 to 1.08. Random forest RMSE and MAE for the validation set are 0.097 and 0.072 respectively which is not low in regards to the actual predicted units, gardient boosting RMSE and the MAE for the validation set are 0.091 and 0.068 which is less.

I decided to keep on using the gradient boosting machine algorithm becasue the benchmark parameters are better for this challenge. 
